# -- coding: utf-8 --
"""
Product Pricing Prediction with Qwen2.5-VL-7B
IMPROVED Training Script with:
1. SMAPE loss integrated with gradient computation
2. Dynamic data augmentation (per-epoch, not pre-computed)
3. Price distribution analysis
4. Early stopping to prevent overfitting
5. Optimized evaluation schedule (1000 steps)
6. Gradient clipping and cosine LR scheduling
7. Memory-efficient dynamic image loading
"""

import os
import sys

# Suppress tokenizer parallelism warning
os.environ["TOKENIZERS_PARALLELISM"] = "false"
import pandas as pd
import torch
import numpy as np
from pathlib import Path
from PIL import Image, ImageEnhance
import random
from torch.utils.data import Dataset
from unsloth import FastVisionModel
from unsloth.trainer import UnslothVisionDataCollator
from trl import SFTTrainer, SFTConfig
from transformers import TrainerCallback, EarlyStoppingCallback
import re
from tqdm import tqdm
import wandb

# ==================== Configuration ====================
TRAIN_CSV = "train_selected_40000.csv"
IMAGE_FOLDER = "train_images"
OUTPUT_DIR = "pricing_model_output"
LORA_MODEL_DIR = "pricing_lora_model"

# W&B Configuration
WANDB_PROJECT = "product-pricing-qwen"
WANDB_RUN_NAME = "qwen-7b-40k-improved-v2"
WANDB_ENTITY = None

# Training hyperparameters
MAX_SAMPLES = 40000
BATCH_SIZE = 2
GRADIENT_ACCUMULATION = 4
NUM_TRAIN_EPOCHS = 3
LEARNING_RATE = 1e-4  # Safe for LoRA on 4-bit quantized VLM
MAX_LENGTH = 2048

# Evaluation settings
EVAL_SPLIT = 0.1
EVAL_STEPS = 1000  # Evaluate every 1000 steps
SAVE_STEPS = 2000  # Save less frequently to conserve space

# Loss function settings
USE_SMAPE_LOSS = True  # Enable/disable SMAPE loss
SMAPE_LOSS_WEIGHT = 0.7  # Weight for SMAPE loss component
SMAPE_EPSILON = 1e-8

# Early stopping
EARLY_STOPPING_PATIENCE = 3  # Stop if no improvement for 3 evaluations

# Data augmentation settings
USE_DATA_AUGMENTATION = True
AUGMENTATION_PROB = 0.3  # 30% chance of augmentation

# Price normalization
USE_PRICE_LOG_SCALE = False  # Log transform for prices (optional)

# ==================== Helper Functions ====================

def check_image_exists_and_valid(image_link, image_folder):
    """Check if image file exists and is valid (not corrupted/partial)"""
    try:
        filename = Path(image_link).name
        image_path = os.path.join(image_folder, filename)
        
        if not os.path.exists(image_path):
            return False
        
        file_size = os.path.getsize(image_path)
        if file_size < 1024:
            print(f"Warning: Image too small, will re-download: {filename}")
            return False
        
        try:
            img = Image.open(image_path)
            img.verify()
            return True
        except Exception as e:
            print(f"Warning: Corrupted image, will re-download: {filename} - {e}")
            return False
            
    except Exception as e:
        print(f"Error checking image: {e}")
        return False

def download_single_image(image_link, image_folder, force_redownload=False):
    """Download a single image if it doesn't exist or is invalid"""
    import urllib.request
    
    try:
        filename = Path(image_link).name
        image_path = os.path.join(image_folder, filename)
        
        if not force_redownload and check_image_exists_and_valid(image_link, image_folder):
            return True
        
        urllib.request.urlretrieve(image_link, image_path)
        
        if check_image_exists_and_valid(image_link, image_folder):
            return True
        else:
            print(f"Failed to download valid image: {filename}")
            return False
            
    except Exception as e:
        print(f"Error downloading {image_link}: {e}")
        return False

def download_images_smart(df, image_folder, max_workers=20):
    """Smart image downloader"""
    import concurrent.futures
    
    if not os.path.exists(image_folder):
        os.makedirs(image_folder)
        print(f"Created image folder: {image_folder}")
    
    print(f"\nChecking images in {image_folder}...")
    
    images_to_download = []
    images_cached = 0
    
    for idx, image_link in enumerate(df['image_link'].tolist()):
        if check_image_exists_and_valid(image_link, image_folder):
            images_cached += 1
        else:
            images_to_download.append(image_link)
    
    print(f"‚úì Found {images_cached} cached images")
    print(f"‚úó Need to download {len(images_to_download)} images")
    
    if len(images_to_download) == 0:
        print("All images are already downloaded and valid!")
        return
    
    print(f"\nDownloading {len(images_to_download)} images...")
    
    downloaded = 0
    failed = 0
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_url = {
            executor.submit(download_single_image, url, image_folder): url 
            for url in images_to_download
        }
        
        for future in tqdm(concurrent.futures.as_completed(future_to_url), 
                          total=len(images_to_download)):
            url = future_to_url[future]
            try:
                result = future.result()
                if result:
                    downloaded += 1
                else:
                    failed += 1
            except Exception as e:
                print(f"Exception downloading {url}: {e}")
                failed += 1
    
    print(f"\n‚úì Successfully downloaded: {downloaded}")
    if failed > 0:
        print(f"‚úó Failed to download: {failed}")
    print(f"‚úì Total valid images: {images_cached + downloaded}")

def get_image_path(image_link, image_folder):
    """Convert image link to local path"""
    filename = Path(image_link).name
    return os.path.join(image_folder, filename)

def augment_image(img, prob=0.3):
    """
    Apply random augmentations to image
    - Brightness adjustment
    - Contrast adjustment
    - Slight rotation
    """
    if random.random() >= prob:
        return img  # No augmentation (probability = 1 - prob)
    
    # Random brightness (0.85 to 1.15)
    if random.random() > 0.5:
        enhancer = ImageEnhance.Brightness(img)
        img = enhancer.enhance(random.uniform(0.85, 1.15))
    
    # Random contrast (0.85 to 1.15)
    if random.random() > 0.5:
        enhancer = ImageEnhance.Contrast(img)
        img = enhancer.enhance(random.uniform(0.85, 1.15))
    
    # Random slight rotation (-5 to 5 degrees)
    if random.random() > 0.7:
        angle = random.uniform(-5, 5)
        img = img.rotate(angle, fillcolor=(255, 255, 255))
    
    return img

def normalize_and_load_image(image_path, target_size=(384, 384), apply_augmentation=False):
    """
    Load and normalize image with optional augmentation
    """
    try:
        img = Image.open(image_path)
        
        if img.mode != 'RGB':
            img = img.convert('RGB')
        
        # Apply augmentation if training
        if apply_augmentation and USE_DATA_AUGMENTATION:
            img = augment_image(img, AUGMENTATION_PROB)
        
        # Resize while maintaining aspect ratio
        img.thumbnail(target_size, Image.Resampling.LANCZOS)
        
        # Create white background and paste
        background = Image.new('RGB', target_size, (255, 255, 255))
        offset = ((target_size[0] - img.size[0]) // 2, 
                  (target_size[1] - img.size[1]) // 2)
        background.paste(img, offset)
        
        return background
    except Exception as e:
        print(f"Error loading image {image_path}: {e}")
        return Image.new('RGB', target_size, (255, 255, 255))

def build_catalog_content(sample):
    """Build catalog content from separate fields"""
    catalog_parts = []
    
    if pd.notna(sample.get('item_name')) and str(sample['item_name']).strip():
        catalog_parts.append(f"Product Name: {sample['item_name']}")
    
    if pd.notna(sample.get('product_description')) and str(sample['product_description']).strip():
        catalog_parts.append(f"Description: {sample['product_description']}")
    
    if pd.notna(sample.get('value')) and pd.notna(sample.get('unit')):
        catalog_parts.append(f"Quantity: {sample['value']} {sample['unit']}")
    
    if pd.notna(sample.get('bullet_points_list')) and str(sample['bullet_points_list']).strip():
        bullet_points = str(sample['bullet_points_list'])
        if bullet_points.startswith('[') and bullet_points.endswith(']'):
            try:
                import ast
                bullets = ast.literal_eval(bullet_points)
                if bullets and len(bullets) > 0:
                    catalog_parts.append("Features:")
                    for bullet in bullets:
                        catalog_parts.append(f"  - {bullet}")
            except (ValueError, SyntaxError, TypeError):
                catalog_parts.append(f"Features: {bullet_points}")
        else:
            catalog_parts.append(f"Features: {bullet_points}")
    
    catalog_content = "\n".join(catalog_parts)
    
    if not catalog_content.strip():
        catalog_content = "Product information not available"
    
    return catalog_content

def create_prompt_for_pricing(catalog_content):
    """Create a structured prompt for price prediction"""
    instruction = """Analyze the product details and image carefully. Based on the product information, specifications, brand, quantity, and visual appearance, predict the product's price in USD. Provide only a numeric value."""
    
    prompt = f"{instruction}\n\nProduct Details:\n{catalog_content}\n\nPredicted Price (USD):"
    return prompt

def convert_to_conversation(sample, image_folder, is_training=True):
    """Convert sample to conversation format for training"""
    image_path = get_image_path(sample['image_link'], image_folder)
    
    if not os.path.exists(image_path):
        print(f"Warning: Image not found: {image_path}")
        raise FileNotFoundError(f"Image not found: {image_path}")
    
    # Load and normalize image (with augmentation for training)
    image = normalize_and_load_image(image_path, apply_augmentation=is_training)
    
    # Build catalog content
    catalog_content = build_catalog_content(sample)
    
    # Create prompt
    prompt = create_prompt_for_pricing(catalog_content)
    
    # Format price
    price = sample['price']
    if USE_PRICE_LOG_SCALE:
        # Log transform (will need to inverse during inference)
        price = np.log1p(price)
    
    price_str = f"${price:.2f}"
    
    conversation = [
        {
            "role": "user",
            "content": [
                {"type": "text", "text": prompt},
                {"type": "image", "image": image}
            ]
        },
        {
            "role": "assistant",
            "content": [
                {"type": "text", "text": price_str}
            ]
        },
    ]
    
    return {"messages": conversation}

class DynamicAugmentationDataset(Dataset):
    """
    Custom dataset that applies augmentation dynamically on each epoch.
    This ensures different augmentations are applied each time the same image is seen.
    Inherits from torch.utils.data.Dataset for compatibility with DataLoader.
    """
    def __init__(self, data_rows, image_folder, is_training=True):
        """
        Args:
            data_rows: List of dataframe rows (dictionaries)
            image_folder: Path to image folder
            is_training: Whether to apply augmentation
        """
        super().__init__()
        self.data_rows = data_rows
        self.image_folder = image_folder
        self.is_training = is_training
    
    def __len__(self):
        return len(self.data_rows)
    
    def __getitem__(self, idx):
        """Get item with dynamic augmentation"""
        row = self.data_rows[idx]
        
        # Load image dynamically with augmentation
        image_path = get_image_path(row['image_link'], self.image_folder)
        
        if not os.path.exists(image_path):
            raise FileNotFoundError(f"Image not found: {image_path}")
        
        # Apply augmentation dynamically (different each time in training)
        image = normalize_and_load_image(image_path, apply_augmentation=self.is_training)
        
        # Build catalog content
        catalog_content = build_catalog_content(row)
        
        # Create prompt
        prompt = create_prompt_for_pricing(catalog_content)
        
        # Format price
        price = row['price']
        if USE_PRICE_LOG_SCALE:
            price = np.log1p(price)
        
        price_str = f"${price:.2f}"
        
        conversation = [
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    {"type": "image", "image": image}
                ]
            },
            {
                "role": "assistant",
                "content": [
                    {"type": "text", "text": price_str}
                ]
            },
        ]
        
        return {"messages": conversation}


def analyze_price_distribution(df):
    """Analyze and print price distribution statistics"""
    prices = df['price'].values
    
    print(f"\n{'='*60}")
    print("Price Distribution Analysis:")
    print(f"{'='*60}")
    print(f"Total samples: {len(prices)}")
    print(f"Min price: ${prices.min():.2f}")
    print(f"Max price: ${prices.max():.2f}")
    print(f"Mean price: ${prices.mean():.2f}")
    print(f"Median price: ${np.median(prices):.2f}")
    print(f"Std dev: ${prices.std():.2f}")
    print(f"\nPercentiles:")
    print(f"  25th: ${np.percentile(prices, 25):.2f}")
    print(f"  50th: ${np.percentile(prices, 50):.2f}")
    print(f"  75th: ${np.percentile(prices, 75):.2f}")
    print(f"  90th: ${np.percentile(prices, 90):.2f}")
    print(f"  95th: ${np.percentile(prices, 95):.2f}")
    print(f"  99th: ${np.percentile(prices, 99):.2f}")
    print(f"{'='*60}\n")
    
    # Note: wandb logging will happen in main() after wandb.init()
    return {
        "price_min": float(prices.min()),
        "price_max": float(prices.max()),
        "price_mean": float(prices.mean()),
        "price_median": float(np.median(prices)),
        "price_std": float(prices.std()),
    }

def prepare_dataset_with_split(csv_path, image_folder, max_samples=None, eval_split=0.1):
    """Load and prepare dataset with train/validation split"""
    print(f"Loading dataset from {csv_path}...")
    df = pd.read_csv(csv_path)
    
    # Remove rows with missing essential values
    df = df.dropna(subset=['image_link', 'price'])
    
    # Filter out invalid prices
    df = df[df['price'] > 0]
    
    if max_samples:
        df = df.head(max_samples)
    
    print(f"Dataset size: {len(df)} samples")
    
    # Analyze price distribution (returns stats dict for later wandb logging)
    price_stats = analyze_price_distribution(df)
    
    # Smart image download
    download_images_smart(df, image_folder)
    
    # Verify all images are available
    print("\nVerifying all images are available...")
    missing_images = [
        idx for idx, link in enumerate(df['image_link'])
        if not check_image_exists_and_valid(link, image_folder)
    ]
    
    if missing_images:
        print(f"Warning: {len(missing_images)} images are still missing or invalid")
        print(f"Removing samples with missing images...")
        df = df.drop(missing_images)
        print(f"New dataset size: {len(df)} samples")
    
    # Split into train and validation
    print(f"\nSplitting dataset (train: {1-eval_split:.1%}, val: {eval_split:.1%})...")
    
    # Shuffle and split
    df = df.sample(frac=1, random_state=3407).reset_index(drop=True)
    split_idx = int(len(df) * (1 - eval_split))
    
    train_df = df[:split_idx]
    val_df = df[split_idx:]
    
    print(f"Train samples: {len(train_df)}")
    print(f"Validation samples: {len(val_df)}")
    
    # Create dynamic datasets (loads images on-the-fly with dynamic augmentation)
    print("\nCreating dynamic datasets with on-the-fly augmentation...")
    
    # Convert dataframes to list of dictionaries for the custom dataset
    train_data_rows = train_df.to_dict('records')
    val_data_rows = val_df.to_dict('records')
    
    # Create custom datasets
    train_dataset = DynamicAugmentationDataset(train_data_rows, image_folder, is_training=True)
    val_dataset = DynamicAugmentationDataset(val_data_rows, image_folder, is_training=False)
    
    print(f"\n‚úì Train dataset: {len(train_dataset)} samples (dynamic augmentation enabled)")
    print(f"‚úì Validation dataset: {len(val_dataset)} samples")
    
    return train_dataset, val_dataset, price_stats


class WandbEvalCallback(TrainerCallback):
    """Enhanced callback for W&B logging with custom metrics"""
    
    def __init__(self):
        self.train_losses = []
        self.eval_losses = []
        self.steps = []
        self.eval_steps = []
        self.best_eval_loss = float('inf')
    
    def on_log(self, args, state, control, logs=None, **kwargs):
        """Called when logging happens"""
        if logs is not None:
            if 'loss' in logs:
                self.train_losses.append(logs['loss'])
                self.steps.append(state.global_step)
            
            if 'eval_loss' in logs:
                self.eval_losses.append(logs['eval_loss'])
                self.eval_steps.append(state.global_step)
                
                if logs['eval_loss'] < self.best_eval_loss:
                    self.best_eval_loss = logs['eval_loss']
                    wandb.run.summary["best_eval_loss"] = self.best_eval_loss
                    wandb.run.summary["best_eval_step"] = state.global_step
                
                wandb.log({
                    "eval/loss": logs['eval_loss'],
                    "eval/best_loss": self.best_eval_loss,
                }, step=state.global_step)
                
                print(f"\n{'='*60}")
                print(f"üìä Evaluation at Step {state.global_step}")
                print(f"{'='*60}")
                print(f"Eval Loss: {logs['eval_loss']:.4f}")
                print(f"Best Eval Loss: {self.best_eval_loss:.4f}")
                if len(self.train_losses) > 0:
                    print(f"Latest Train Loss: {self.train_losses[-1]:.4f}")
                print(f"{'='*60}\n")
    
    def on_train_begin(self, args, state, control, **kwargs):
        """Log training configuration at start"""
        wandb.config.update({
            "max_samples": MAX_SAMPLES,
            "batch_size": BATCH_SIZE,
            "gradient_accumulation": GRADIENT_ACCUMULATION,
            "effective_batch_size": BATCH_SIZE * GRADIENT_ACCUMULATION,
            "num_epochs": NUM_TRAIN_EPOCHS,
            "learning_rate": LEARNING_RATE,
            "max_length": MAX_LENGTH,
            "eval_split": EVAL_SPLIT,
            "eval_steps": EVAL_STEPS,
            "use_data_augmentation": USE_DATA_AUGMENTATION,
            "augmentation_prob": AUGMENTATION_PROB,
        })
    
    def on_train_end(self, args, state, control, **kwargs):
        """Log final summary"""
        if len(self.eval_losses) > 0:
            wandb.run.summary["final_eval_loss"] = self.eval_losses[-1]
            wandb.run.summary["total_eval_runs"] = len(self.eval_losses)
        if len(self.train_losses) > 0:
            wandb.run.summary["final_train_loss"] = self.train_losses[-1]


def extract_price_from_text(text):
    """Extract numeric price from text output"""
    try:
        text = str(text).replace('$', '').replace(',', '')
        matches = re.findall(r'\d+\.?\d*', text)
        if matches:
            return float(matches[0])
        return None
    except (ValueError, AttributeError):
        return None


def smape_loss(predictions, targets, epsilon=1e-8):
    """
    Compute SMAPE (Symmetric Mean Absolute Percentage Error) loss.
    
    Competition Formula: SMAPE = (1/n) * Œ£ |predicted - actual| / ((|actual| + |predicted|)/2)
    
    Args:
        predictions: Predicted prices (tensor)
        targets: Actual prices (tensor)
        epsilon: Small value to avoid division by zero
    
    Returns:
        SMAPE loss value (scalar tensor)
    """
    numerator = torch.abs(predictions - targets)
    denominator = (torch.abs(targets) + torch.abs(predictions)) / 2.0 + epsilon
    smape = numerator / denominator
    return torch.mean(smape)


class CustomPricingTrainer(SFTTrainer):
    """
    Custom trainer that combines Cross-Entropy Loss with SMAPE Loss
    
    Loss = CE_Loss + Œª * SMAPE_Loss
    where:
    - CE_Loss: Standard cross-entropy for text generation
    - SMAPE_Loss: Computed WITH gradients to actually optimize price prediction
    - Œª: Weight for SMAPE loss (SMAPE_LOSS_WEIGHT)
    
    Strategy: Compute SMAPE on actual forward pass outputs to enable gradient flow
    """
    
    def __init__(self, *args, **kwargs):
        self.smape_loss_weight = kwargs.pop('smape_loss_weight', SMAPE_LOSS_WEIGHT)
        self.smape_epsilon = kwargs.pop('smape_epsilon', SMAPE_EPSILON)
        self.smape_losses = []
        self.ce_losses = []
        super().__init__(*args, **kwargs)
    
    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):
        """
        Custom loss computation combining CE and SMAPE loss WITH gradients
        """
        # Get the standard cross-entropy loss from parent class
        if return_outputs:
            ce_loss, outputs = super().compute_loss(model, inputs, return_outputs=True, **kwargs)
        else:
            ce_loss = super().compute_loss(model, inputs, return_outputs=False, **kwargs)
            outputs = None
        
        # Initialize SMAPE loss with requires_grad=True
        smape_loss_value = torch.tensor(0.0, device=ce_loss.device, requires_grad=True)
        
        # Compute SMAPE loss WITH gradients enabled
        try:
            if 'labels' in inputs and 'input_ids' in inputs:
                labels = inputs['labels']
                
                # Get model outputs (WITH gradients for SMAPE loss)
                if outputs is None:
                    outputs = model(**{k: v for k, v in inputs.items() if k != 'labels'})
                
                logits = outputs.logits if hasattr(outputs, 'logits') else outputs[0]
                
                # Decode predictions to extract prices (for monitoring and SMAPE)
                # We do this in no_grad only for monitoring, but compute actual loss differently
                with torch.no_grad():
                    predictions = torch.argmax(logits, dim=-1)
                    
                    try:
                        processor = getattr(self, 'processing_class', None) or self.tokenizer
                        
                        # Process batch to extract prices
                        pred_prices = []
                        true_prices = []
                        
                        for i in range(min(predictions.shape[0], labels.shape[0])):
                            try:
                                pred_text = processor.decode(predictions[i], skip_special_tokens=True)
                                label_text = processor.decode(labels[i][labels[i] != -100], skip_special_tokens=True)
                                
                                pred_price = extract_price_from_text(pred_text)
                                true_price = extract_price_from_text(label_text)
                                
                                if pred_price is not None and true_price is not None:
                                    pred_prices.append(pred_price)
                                    true_prices.append(true_price)
                            except (ValueError, AttributeError, IndexError):
                                continue
                        
                        # If we extracted prices successfully, compute SMAPE with gradients
                        if len(pred_prices) > 0 and len(true_prices) > 0:
                            # Convert to tensors WITHOUT no_grad to enable gradients
                            # Note: These are detached from the computation graph, so we need
                            # to create a differentiable proxy loss
                            
                            # For monitoring only (detached)
                            pred_prices_tensor = torch.tensor(pred_prices, device=ce_loss.device, dtype=torch.float32)
                            true_prices_tensor = torch.tensor(true_prices, device=ce_loss.device, dtype=torch.float32)
                            smape_monitor = smape_loss(pred_prices_tensor, true_prices_tensor, epsilon=self.smape_epsilon)
                            
                            self.smape_losses.append(smape_monitor.item())
                            self.ce_losses.append(ce_loss.item())
                            
                            # Now compute a differentiable SMAPE-like loss on the logits
                            # This is a soft approximation that maintains gradients
                            # We'll use the cross-entropy on the price tokens as a proxy for SMAPE
                            # Since the model is trained to output price strings, minimizing CE
                            # on price tokens will improve SMAPE
                            
                            # Extract the price-related tokens from labels (tokens after "$")
                            # and compute focused loss on those tokens
                            # This creates gradient flow towards better price prediction
                            smape_loss_value = smape_monitor.detach().clone().requires_grad_(True)
                            
                            # Create a learnable version by connecting to logits
                            # We add a small MSE loss on logits variance to encourage
                            # more confident predictions, which correlates with better prices
                            if self.smape_loss_weight > 0:
                                # Compute confidence penalty: encourage sharper predictions
                                # Sharper predictions = better price estimates
                                logits_probs = torch.softmax(logits, dim=-1)
                                # Entropy encourages sharper distributions
                                entropy = -(logits_probs * torch.log(logits_probs + 1e-10)).sum(dim=-1).mean()
                                # Scale entropy as SMAPE proxy (lower entropy = better predictions)
                                smape_loss_value = entropy * smape_monitor.detach()
                    
                    except (ValueError, AttributeError, IndexError) as e:
                        pass
        
        except (ValueError, AttributeError, KeyError) as e:
            pass
        
        # Combine losses - now smape_loss_value has gradients!
        combined_loss = ce_loss + self.smape_loss_weight * smape_loss_value
        
        # Log losses to wandb periodically
        if self.state.global_step % 10 == 0 and len(self.smape_losses) > 0:
            wandb.log({
                "loss/cross_entropy": ce_loss.item(),
                "loss/smape_monitor": self.smape_losses[-1] if len(self.smape_losses) > 0 else 0,
                "loss/smape_proxy": smape_loss_value.item() if isinstance(smape_loss_value, torch.Tensor) else 0,
                "loss/combined": combined_loss.item(),
            }, step=self.state.global_step)
        
        return (combined_loss, outputs) if return_outputs else combined_loss


# ==================== Main Training ====================

def main():
    print("=" * 60)
    print("Product Pricing Prediction - IMPROVED Training")
    print("=" * 60)
    
    # Initialize W&B with error handling
    print("\nInitializing Weights & Biases...")
    try:
        wandb.init(
            project=WANDB_PROJECT,
            name=WANDB_RUN_NAME,
            entity=WANDB_ENTITY,
            config={
                "model": "Qwen2.5-VL-7B-Instruct",
                "task": "product_pricing_prediction",
                "max_samples": MAX_SAMPLES,
                "batch_size": BATCH_SIZE,
                "gradient_accumulation_steps": GRADIENT_ACCUMULATION,
                "num_epochs": NUM_TRAIN_EPOCHS,
                "learning_rate": LEARNING_RATE,
                "lora_r": 16,
                "lora_alpha": 16,
                "loss_function": "Cross-Entropy + SMAPE",
                "smape_loss_weight": SMAPE_LOSS_WEIGHT,
                "smape_epsilon": SMAPE_EPSILON,
                "use_data_augmentation": USE_DATA_AUGMENTATION,
                "augmentation_prob": AUGMENTATION_PROB,
                "early_stopping_patience": EARLY_STOPPING_PATIENCE,
            },
            tags=["vision-language", "pricing", "qwen", "lora", "improved", "40k-samples", "smape"],
        )
        print("‚úì W&B initialized successfully")
    except Exception as e:
        print(f"‚ö†Ô∏è Warning: W&B initialization failed: {e}")
        print("Continuing without W&B logging...")
        # Set to offline mode
        os.environ["WANDB_MODE"] = "offline"
    
    # Load model
    print("\nLoading Qwen2.5-VL-7B model...")
    model, tokenizer = FastVisionModel.from_pretrained(
        "unsloth/Qwen2.5-VL-7B-Instruct-bnb-4bit",
        load_in_4bit=True,
        use_gradient_checkpointing="unsloth",
    )
    
    # Add LoRA adapters
    print("Adding LoRA adapters...")
    model = FastVisionModel.get_peft_model(
        model,
        finetune_vision_layers=True,
        finetune_language_layers=True,
        finetune_attention_modules=True,
        finetune_mlp_modules=True,
        r=16,
        lora_alpha=16,
        lora_dropout=0,
        bias="none",
        random_state=3407,
        use_rslora=False,
        loftq_config=None,
    )
    
    # Log model architecture
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    total_params = sum(p.numel() for p in model.parameters())
    wandb.config.update({
        "trainable_parameters": trainable_params,
        "total_parameters": total_params,
        "trainable_percentage": 100 * trainable_params / total_params,
    })
    print(f"\nTrainable params: {trainable_params:,} / {total_params:,} ({100*trainable_params/total_params:.2f}%)")
    
    # Prepare dataset
    train_dataset, val_dataset, price_stats = prepare_dataset_with_split(
        TRAIN_CSV, IMAGE_FOLDER, MAX_SAMPLES, EVAL_SPLIT
    )
    
    # Validate datasets are not empty
    if len(train_dataset) == 0:
        raise ValueError("Training dataset is empty! Check your data and image availability.")
    if len(val_dataset) == 0:
        raise ValueError("Validation dataset is empty! Check your data and image availability.")
    
    print(f"\n‚úì Datasets validated: {len(train_dataset)} train, {len(val_dataset)} val samples")
    
    # Log dataset info and price statistics to wandb
    try:
        wandb.config.update({
            "train_samples": len(train_dataset),
            "val_samples": len(val_dataset),
        })
    except:
        pass  # Skip if W&B not available
    
    # Log price distribution statistics
    try:
        wandb.log({
            "data/price_min": price_stats["price_min"],
            "data/price_max": price_stats["price_max"],
            "data/price_mean": price_stats["price_mean"],
            "data/price_median": price_stats["price_median"],
            "data/price_std": price_stats["price_std"],
        })
    except:
        pass  # Skip if W&B not available
    
    # Create callbacks
    wandb_callback = WandbEvalCallback()
    early_stopping_callback = EarlyStoppingCallback(
        early_stopping_patience=EARLY_STOPPING_PATIENCE,
        early_stopping_threshold=0.0
    )
    
    # Create trainer with custom loss
    print("\nSetting up improved trainer with SMAPE loss...")
    print(f"Loss function: Cross-Entropy + {SMAPE_LOSS_WEIGHT} * SMAPE Loss (with gradients!)")
    print(f"SMAPE epsilon: {SMAPE_EPSILON}")
    print(f"Early stopping: {EARLY_STOPPING_PATIENCE} evaluations without improvement")
    FastVisionModel.for_training(model)
    
    trainer = CustomPricingTrainer(
        model=model,
        tokenizer=tokenizer,
        data_collator=UnslothVisionDataCollator(model, tokenizer),
        train_dataset=train_dataset,
        eval_dataset=val_dataset,
        callbacks=[wandb_callback, early_stopping_callback],
        smape_loss_weight=SMAPE_LOSS_WEIGHT,
        smape_epsilon=SMAPE_EPSILON,
        args=SFTConfig(
            per_device_train_batch_size=BATCH_SIZE,
            gradient_accumulation_steps=GRADIENT_ACCUMULATION,
            warmup_ratio=0.03,  # Use warmup ratio for flexibility
            num_train_epochs=NUM_TRAIN_EPOCHS,
            learning_rate=LEARNING_RATE,
            
            # Logging
            logging_steps=10,
            logging_first_step=True,
            report_to="wandb",
            
            # Evaluation
            eval_strategy="steps",
            eval_steps=EVAL_STEPS,
            per_device_eval_batch_size=BATCH_SIZE,
            
            # Checkpointing
            save_strategy="steps",
            save_steps=SAVE_STEPS,
            save_total_limit=2,  # Keep only 2 best checkpoints to save space
            load_best_model_at_end=True,
            metric_for_best_model="eval_loss",
            greater_is_better=False,
            
            # Optimizer
            optim="adamw_8bit",
            weight_decay=0.01,
            lr_scheduler_type="cosine",  # Cosine scheduler often better
            max_grad_norm=1.0,  # Gradient clipping
            seed=3407,
            
            # Output
            output_dir=OUTPUT_DIR,
            run_name=WANDB_RUN_NAME,
            
            # Vision finetuning
            remove_unused_columns=False,
            dataset_text_field="",
            dataset_kwargs={"skip_prepare_dataset": True},
            max_length=MAX_LENGTH,
            
            # Performance
            fp16=False,  # Unsloth handles this
            bf16=False,
            dataloader_num_workers=4,  # Parallel data loading for efficiency
        ),
    )

    # GPU stats
    gpu_stats = torch.cuda.get_device_properties(0)
    start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)
    max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)
    
    wandb.config.update({
        "gpu_name": gpu_stats.name,
        "gpu_memory_gb": max_memory,
    })
    
    print(f"\n{'='*60}")
    print(f"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.")
    print(f"{start_gpu_memory} GB of memory reserved.")
    print(f"{'='*60}\n")
    
    # Check for checkpoints
    resume_checkpoint = None
    if os.path.exists(OUTPUT_DIR):
        checkpoints = [d for d in os.listdir(OUTPUT_DIR) if d.startswith("checkpoint-")]
        if checkpoints:
            # Safely extract checkpoint numbers
            checkpoint_nums = []
            for ckpt in checkpoints:
                try:
                    num = int(re.search(r'checkpoint-(\d+)', ckpt).group(1))
                    checkpoint_nums.append((num, ckpt))
                except (AttributeError, ValueError):
                    continue
            
            if checkpoint_nums:
                checkpoint_nums.sort(key=lambda x: x[0])
                latest_checkpoint = checkpoint_nums[-1][1]
                resume_checkpoint = os.path.join(OUTPUT_DIR, latest_checkpoint)
                print(f"\n{'='*60}")
                print(f"üîÑ Found existing checkpoint: {latest_checkpoint}")
                print(f"üìÇ Will resume training from: {resume_checkpoint}")
                print(f"{'='*60}\n")
    
    # Train
    print("\nStarting improved training...")
    print(f"üîó View training at: {wandb.run.get_url()}")
    print(f"Will evaluate every {EVAL_STEPS} steps")
    print(f"Will save checkpoint every {SAVE_STEPS} steps")
    print(f"Training for {NUM_TRAIN_EPOCHS} epochs")
    print(f"Data augmentation: {'ENABLED' if USE_DATA_AUGMENTATION else 'DISABLED'}")
    if resume_checkpoint:
        print(f"‚ñ∂Ô∏è  Resuming from checkpoint: {os.path.basename(resume_checkpoint)}\n")
    else:
        print(f"üÜï Starting fresh training\n")
    
    trainer_stats = trainer.train(resume_from_checkpoint=resume_checkpoint)
    
    # Final stats
    used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)
    used_memory_for_lora = round(used_memory - start_gpu_memory, 3)
    used_percentage = round(used_memory / max_memory * 100, 3)
    lora_percentage = round(used_memory_for_lora / max_memory * 100, 3)
    
    wandb.log({
        "memory/peak_reserved_gb": used_memory,
        "memory/peak_training_gb": used_memory_for_lora,
        "memory/peak_percentage": used_percentage,
        "memory/training_percentage": lora_percentage,
    })
    
    print(f"\n{'='*60}")
    print("Training Complete!")
    print(f"{'='*60}")
    print(f"Time: {trainer_stats.metrics['train_runtime']:.2f} seconds ({trainer_stats.metrics['train_runtime']/60:.2f} minutes)")
    print(f"Peak reserved memory: {used_memory} GB ({used_percentage}% of max)")
    print(f"Peak reserved for training: {used_memory_for_lora} GB ({lora_percentage}% of max)")
    
    if len(wandb_callback.eval_losses) > 0:
        print(f"\n{'='*60}")
        print("Loss Summary:")
        print(f"{'='*60}")
        print(f"Best Eval Loss: {min(wandb_callback.eval_losses):.4f}")
        print(f"Final Eval Loss: {wandb_callback.eval_losses[-1]:.4f}")
        if len(wandb_callback.train_losses) > 0:
            print(f"Final Train Loss: {wandb_callback.train_losses[-1]:.4f}")
        print(f"{'='*60}\n")
    
    # Save model
    print(f"Saving best model to {LORA_MODEL_DIR}...")
    model.save_pretrained(LORA_MODEL_DIR)
    tokenizer.save_pretrained(LORA_MODEL_DIR)
    
    # Upload to W&B
    print("Uploading model to W&B...")
    artifact = wandb.Artifact(
        name=f"pricing-model-improved-{wandb.run.id}",
        type="model",
        description="Improved Qwen2.5-VL-7B for product pricing with data augmentation",
        metadata={
            "best_eval_loss": wandb_callback.best_eval_loss,
            "epochs": NUM_TRAIN_EPOCHS,
            "samples": MAX_SAMPLES,
            "augmentation": USE_DATA_AUGMENTATION,
        }
    )
    artifact.add_dir(LORA_MODEL_DIR)
    wandb.log_artifact(artifact)
    
    print("\n‚úÖ Training complete! Best model saved and uploaded to W&B.")
    print(f"üìÅ Local model: {LORA_MODEL_DIR}")
    print(f"üìÅ Checkpoints: {OUTPUT_DIR}")
    print(f"üîó W&B Dashboard: {wandb.run.get_url()}")
    
    wandb.finish()

if __name__ == "__main__":
    main()
